import os; os. environ['KMP_DUPLICATE_LIB_OK']='TRUE'
import pandas as pd
import numpy as np
import torch
from torch.utils.data import DataLoader,TensorDataset
from matplotlib import pyplot as plt
from torchmetrics.functional import r2_score  # 此库进行r2分数计算
import seaborn as sns  # 此库进行热力图和pairplot图绘制

#读取原始数据
o_train_Bb = pd.read_csv('train-all.csv')
o_test_Bb = pd.read_csv('test-all.csv')
data = pd.read_csv('all.csv')

# 绘制pairplot图
sns.pairplot(data)

# 绘制热力图
dt_coor=data.corr()
plt.subplots(figsize=(15,15),dpi=1080,facecolor='w')# 设置画布大小，分辨率，和底色
fig=sns.heatmap(dt_coor,annot=True, vmax=1, square=True, cmap="RdBu_r", fmt='.2g')#annot为热力图上显示数据；fmt='.2g'为数据保留两位有效数字,square呈现正方形，vmax最大值为1
fig

# 数据处理
all_features = pd.concat((o_train_Bb.loc[:,'KH':'aM'],o_test_Bb.loc[:,'KH':'aM']))
all_labels = pd.concat((o_train_Bb.loc[:,'Bb'],o_test_Bb.loc[:,'Bb']))
print(all_labels.shape)
print(all_features.head())

#对特征值进行数据预处理
# 取出所有的数值型特征名称
numeric_feats = all_features.dtypes[all_features.dtypes != "object"].index
# 将数值型特征进行 z-score 标准化
all_features[numeric_feats] = all_features[numeric_feats].apply(lambda x: (x - x.mean()) / (x.std()))
#对无序型进行one-hot encoding
all_features = pd.get_dummies(all_features, dummy_na=True)
#空值：每一个特征的全局平均值来代替无效值 NA就是指空值
all_features = all_features.fillna(all_features.mean())

#对标签进行数据预处理
#对标签进行 z-score 标准化
mean = all_labels.mean()
std = all_labels.std()
all_labels = (all_labels - mean)/std

# 将numpy数据转换为tensor
num_train = o_train_Bb.shape[0]
train_features = torch.tensor(all_features[:num_train].values, dtype=torch.float32)
test_features = torch.tensor(all_features[num_train:].values, dtype=torch.float32)
train_labels = torch.tensor(all_labels[:num_train].values.reshape(-1, 1), dtype=torch.float32)
test_labels = torch.tensor(all_labels[num_train:].values.reshape(-1, 1), dtype=torch.float32)

# 设置测试集和训练集
train_set = TensorDataset(train_features,train_labels)
test_set = TensorDataset(test_features,test_labels)

#设置迭代器
train_data = DataLoader(dataset=train_set,batch_size=32,shuffle=True)
test_data  = DataLoader(dataset=test_set,batch_size=32,shuffle=True)

#构建网络结构
class Net(torch.nn.Module):# 继承 torch 的 Module
    def __init__(self, in_features):
        super(Net, self).__init__()     # 继承 __init__ 功能
        # 定义每层用什么样的形式
        self.layer1 = torch.nn.Linear(in_features, 64)
        self.layer2 = torch.nn.Linear(64, 128)
        self.layer3 = torch.nn.Linear(128, 256)
        self.layer4 = torch.nn.Linear(256, 256)
        self.layer5 = torch.nn.Linear(256, 128)
        self.layer6 = torch.nn.Linear(128, 64)
        self.out = torch.nn.Linear(64, 1)

    def forward(self, x):
        x = self.layer1(x)
        x = torch.relu(x)
        
        x = self.layer2(x)
        x = torch.relu(x)
        
        x = self.layer3(x)
        x = torch.relu(x)
        
        x = self.layer4(x)
        x = torch.relu(x)
        
        x = self.layer5(x)
        x = torch.relu(x)
        
        x = self.layer6(x)
        x = torch.relu(x)
        
        x = self.out(x)
        return x
net = Net(in_features = 8)

#反向传播算法 SGD Adam等
optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay = 0.01)
#均方损失函数
criterion =	torch.nn.MSELoss()

#记录用于绘图
train_loss = [] #记录每次迭代后训练的loss
test_loss = [] #记录每次迭代后测试的loss
train_r2 = [] # 记录训练的r2分数

num_epochs = 150
for i in range(num_epochs):
    tr_loss = 0 # 把一个batch size的loss进行加和
    tr_r2 = 0 # 把一个batch size的r2分数进行加和
    net.train() # 训练模式
    for tdata,tlabel in train_data:
        #前向传播
        y_ = net(tdata)
        loss = criterion(y_, tlabel)
        #反向传播
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        tr_r2 = tr_r2 + r2_score(y_, tlabel).item() #累计单批次误差
        tr_loss = tr_loss + loss.item() #累计单批次r2分数

    train_loss.append(tr_loss / len(train_data)) # 将一个批次的loss取平均记录到list中
    train_r2.append(tr_r2 / len(train_data)) # 将一个批次的r2取平均记录到list中
    
    # 测试集进行测试
    te_loss = 0
    net.eval()  # 测试模式
    with torch.no_grad():  # 测试集不需要进行反向传播更新网络
        for edata, elabel in test_data:
            # 前向传播
            y_ = net(edata)
            loss = criterion(y_, elabel)
            # 累计单批次误差
            te_loss = te_loss + loss.item()
        test_loss.append(te_loss / len(test_data))
    
    print('epoch: {}, train loss: {:.3f}, test loss: {:.3f}, train r2: {:.3f}'.format(i+1, train_loss[i], 
                                                                          test_loss[i], train_r2[i]))
# 计算平均loss和r2
print(f'avg train loss is {sum(train_loss) / len(train_loss) : .3f}')
print(f'test loss is {sum(test_loss) / len(test_loss) : .3f}')
print(f'train r2 is {sum(train_r2) / len(train_r2) : .3f}')

# 把list数据转换为numpy数据以便进行画图
l_s = np.array(train_loss).reshape(150, -1)
epochs = [range(1, 150+1)]
ep = np.array(epochs).reshape(150, -1)
e_l = np.array(test_loss).reshape(150, -1)

# 绘制loss图
x_axix = ep
train_axiy = l_s
test_axiy = e_l
fig = plt.figure(figsize = (8, 5))
plt.title('Bb-NN')
plt.plot(x_axix, train_axiy, color='green', label='train loss', linewidth = 2)
plt.plot(x_axix, test_axiy, color='red', label='test loss', linewidth = 2)
plt.legend()
plt.xlabel('epoch')
plt.ylabel('Loss')
plt.show()

# 绘制r2图
x_axix = ep
tr_r2_axiy = tr_r2
fig = plt.figure(figsize = (8, 5))
plt.title('Bb-R2')
plt.plot(x_axix, tr_r2_axiy, color='red', label='train r2', linewidth = 2)
plt.legend()
plt.xlabel('epoch')
plt.ylabel('R2')
plt.show()
